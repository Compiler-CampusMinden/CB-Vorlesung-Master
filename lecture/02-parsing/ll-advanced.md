# LL-Parser: Fortgeschrittene Techniken

> [!IMPORTANT]
>
> <details open>
>
> <summary><strong>üéØ TL;DR</strong></summary>
>
> <img src="https://github.com/Compiler-CampusMinden/CPL-Vorlesung-Master/blob/master/lecture/02-parsing/images/architektur_cb_parser.png?raw=true">
>
> Man kann einen LL(k)-Parser bei Bedarf um ein ‚Äúspekulatives Matching‚Äù
> erg√§nzen. Dies ist in Situationen relevant, wo man das $`k`$ nicht
> vorhersehen kann, etwa bei der Unterscheidung einer
> Vorw√§rtsdeklaration und einer Funktionsdefinition in C. Hier kann man
> erst nach dem Parsen des Funktionsnamens entscheiden, welche Situation
> vorliegt; der Funktionsname kann dabei (nahezu) beliebig lang sein.
>
> Beim spekulativen Matching muss man sich merken, an welcher Position
> im Tokenstrom man die Spekulation gestartet hat, um im Fall des
> Nichterfolgs dorthin wieder zur√ºckspringen zu k√∂nnen (‚ÄúBacktracking‚Äù).
>
> Das Backtracking kann sehr langsam werden durch das Ausprobieren
> mehrerer Alternativen und das jeweils n√∂tige Zur√ºckrollen. Zudem kann
> es passieren, dass eine bestimmte Sequenz immer wieder erkannt werden
> muss. Hier hilft eine weitere Technik: **Packrat Parsing** ([Ford
> 2006](#ref-Packrat2006)) (nutzt
> [‚Äú*memoisation*‚Äù](https://en.wikipedia.org/wiki/Memoization)). Hierbei
> f√ºhrt man pro Regel eine Map mit, in der zu einer Position im
> Tokenstrom festgehalten wird, ob diese Regel an/ab dieser Position
> bereits erfolgreich oder nicht erfolgreich war. Dies kann man dann
> nutzen, um bei einem erneuten Parsen der selben Regel ‚Äúvorzuspulen‚Äù.
>
> In ANTLR kann man *semantische Pr√§dikate* benutzen, um Alternativen
> ‚Äúabzuschalten‚Äù. Dies ist beispielsweise n√ºtzlich, wenn man nur eine
> Grammatik f√ºr unterschiedliche Versionen einer Sprache implementieren
> will.
>
> Eine gute Darstellung finden Sie in ([Parr 2010](#ref-Parr2010))
> (Kapitel 3) und in ([Ford 2006](#ref-Packrat2006)).
>
> </details>

> [!TIP]
>
> <details>
>
> <summary><strong>üé¶ Videos</strong></summary>
>
> - [VL LL-Parser: Fortgeschrittene
>   Techniken](https://youtu.be/12GT2WxZsxY)
>
> </details>

## LL-Parser mit Backtracking

Problem: Manchmal kennt man den n√∂tigen Lookahead nicht vorher.
Beispiel:

``` cpp
wuppie();         // Vorw√§rtsdeklaration
wuppie() { ...}   // Definition
```

Entsprechend s√§he die Grammatik aus:

``` antlr
func : fdef | fdecl ;
fdef : head '{' body '}' ;
fdecl: head ';' ;
head : ... ;
```

Hier m√ºsste man erst den gesamten Funktionskopf parsen, bevor man
entscheiden kann, ob es sich um eine Deklaration oder eine Definition
handelt. Ungl√ºcklicherweise gibt es keine L√§ngenbeschr√§nkung bei den
Funktionsnamen ‚Ä¶

Mit Hilfe von Backtracking kann man zun√§chst spekulativ matchen und beim
Auftreten eines Fehlers die Spekulation r√ºckg√§ngig machen:

``` python
def func():
    if speculate(fdef): fdef()      # Spekuliere auf "fdef"
    elif speculate(fdecl): fdecl()  # Spekuliere auf "fdecl"
    else: raise Exception()
```

Die erste Alternative, die passt, gewinnt. √úber die Reihenfolge der
Spekulationen kann man entsprechend Vorrangregeln implementieren.

### Anmerkung

Man k√∂nnte die obige Grammatik umformen ‚Ä¶

``` antlr
func : head ('{' body '}' | ';') ;
head : ... ;
```

‚Ä¶und br√§uchte dann kein spekulatives Parsen mit Backtracking.

Da wir aber das Parsen mit Backtracking betrachten wollen, blenden wir
diese M√∂glichkeit jetzt einfach aus ;)

## Details: Spekulatives Matchen

``` python
def speculate(fn):
    success = True

    mark()                  # markiere aktuelle Position

    try:   fn()             # probiere Regel fn()
    catch: success = False

    clear()                 # Rollback

    return success
```

Quelle: Eigener Code basierend auf einer Idee nach ([Parr
2010](#ref-Parr2010), p.¬†60)

Der Funktion `speculate` wird die zu testende Regel (Funktion) als
Parameter √ºbergeben, im obigen Beispiel w√§ren dies `fdef` bzw. `fdecl`.

Vor dem spekulativen Matchen muss die aktuelle Position im Tokenstrom
markiert werden. Falls der Versuch, die Deklaration zu matchen nicht
funktioniert, wird der Regel-Aufruf eine Exception werfen, entsprechend
wird die Hilfsvariable gesetzt. Anschlie√üend muss noch mit `clear()` das
aktuelle Token wieder hergestellt werden (wir sind ja nur im
Spekulationsmodus, d.h. selbst im Erfolgsfall wird ja die Regel noch
‚Äúrichtig‚Äù aufgerufen).

## Spekulatives Matchen: Hilfsmethoden I/II

``` python
class Parser:
    Lexer lexer
    markers = []    # Integer-Stack: speichere Tokenpositionen
    lookahead = []  # Puffer (1 Token vorbef√ºllt via Konstruktor)
    start = 0       # aktuelle Tokenposition im lookahead-Puffer

    def mark():
        markers.push(start)

    def clear():
        start = markers.pop()
```

Quelle: Eigener Code basierend auf einer Idee nach ([Parr
2010](#ref-Parr2010), pp.¬†61/62)

## Spekulatives Matchen: Hilfsmethoden II/II

``` python
def consume():
    ++start
    if start == lookahead.count() and markers.isEmpty():
        start = 0; lookahead.clear()
    sync(1)

def lookahead(i):
    sync(i)
    return lookahead.get(start+i-1)

def sync(i):
    n = start + i - lookahead.count()
    while (n > 0):
        lookahead.add(lexer.nextToken()); --n
```

Quelle: Eigener Code basierend auf einer Idee nach ([Parr
2010](#ref-Parr2010), pp.¬†61/62)

`consume` holt wie immer das n√§chste Token, hier indem der Index `start`
weiter gesetzt wird und ein weiteres Token √ºber `sync` in den Puffer
geladen wird. Falls wir nicht am Spekulieren sind und das Ende des
Puffers erreicht haben, nutzen wir die Gelegenheit und setzen den Puffer
zur√ºck. (Dies geht nicht, wenn wir spekulieren ‚Äì hier m√ºssen wir ja ggf.
ein Rollback vornehmen und ben√∂tigen also den aktuellen Puffer dann
noch.)

Die Funktion `sync` stellt sicher, dass ab der Position `start` noch `i`
unverbrauchte Token im Puffer sind.

### Hinweis

Die Methode `count` liefert die Anzahl der aktuell gespeicherten
Elemente in `lookahead` zur√ºck (nicht die Gesamtzahl der Pl√§tze in der
Liste ‚Äì diese kann gr√∂√üer sein). Mit der Methode `add` wird ein Element
hinten an die Liste angef√ºgt, dabei wird das Token auf den n√§chsten
Index-Platz (`count`) geschrieben und ggf. die Liste ggf. automatisch um
weitere Speicherpl√§tze erg√§nzt. √úber `clear` werden die Elemente in der
Liste gel√∂scht, aber der Speicherplatz erhalten (d.h. `count()` liefert
den Wert 0, aber ein `add` m√ºsste nicht erst die Liste mit weiteren
Pl√§tzen erweitern, sondern k√∂nnte direkt an Index 0 das Token
schreiben).

### Backtracking f√ºhrt zu Problemen

1.  Backtracking kann *sehr* langsam sein (Ausprobieren vieler
    Alternativen)
2.  Der spekulative Match muss ggf. r√ºckg√§ngig gemacht werden
3.  Man muss bereits gematchte Strukturen erneut matchen (=\> Abhilfe:
    Packrat-Parsing)

## Verbesserung Backtracking: Packrat Parser (Memoizing)

<img src="images/packrat.png" width="60%">

Bei der Eingabe `wuppie();` wird zun√§chst spekulativ die erste
Alternative `fdef` untersucht und ein `head` gematcht. Da die
Alternative nicht komplett passt (es kommt ein ‚Äú;‚Äù statt einem ‚Äú{‚Äù),
muss die Spekulation r√ºckg√§ngig gemacht werden und die zweite
Alternative `fdecl` untersucht werden. Dabei muss man den selben Input
erneut auf `head` matchen! (Und wenn die Spekulation (irgendwann)
erfolgreich war, muss noch einmal ein `head` gematcht werden ‚Ä¶)

Idee: Wenn `head` sich merken w√ºrde, ob damit ein bestimmter Teil des
Tokenstroms bereits behandelt wurde (erfolgreich oder nicht), k√∂nnte man
das Spekulieren effizienter gestalten. Jede Regel muss also durch eine
passende Regel mit Speicherung erg√§nzt werden.

Dies wird auch als
[‚ÄúMemoization‚Äù](https://en.wikipedia.org/wiki/Memoization) bezeichnet
und ist eine zentrales Technik des Packrat Parsers (vgl. Ford
([2006](#ref-Packrat2006))).

## Skizze: Idee des Packrat-Parsing

``` python
head_memo = {}

def head():
    if head_memo.get(start) == -1:
        raise Exception()                         # kein Match
    if head_memo.get(start) >= 0:
        start = head_memo[start]; return True     # Vorspulen
    else:
        failed = False; start_ = start
        try: ...     # rufe die urspr√ºngliche head()-Regel auf
        catch(e): failed = True; raise e
        finally: head_memo[start_] = (failed ? -1 : start)
```

Quelle: Eigener Code basierend auf einer Idee nach ([Parr
2010](#ref-Parr2010), pp.¬†65/66)

- Wenn bereits untersucht (Eintrag vorhanden): Vorspulen bzw. Exception
  werfen
- Sonst (aktuelle Position noch nicht in der Tabelle =\> Regel noch
  nicht an dieser Position getestet):
  - Original-Regel ausf√ºhren
  - Exception: Regel hatte keinen Erfolg =\> merken und Exception weiter
    reichen
- Ergebnis f√ºr diese Startposition und diese Regel merken:
  - Falls Regel erfolgreich, dann Start-Position und die aktuelle
    Position (Stopp-Position) in der Tabelle f√ºr diese Regel notieren
  - Falls Regel nicht erfolgreich, zur Start-Position eine ung√ºltige
    Position setzen

### Anmerkung *consume()*

Die Funktion `consume()` muss passend erg√§nzt werden: Wann immer man den
`lookahead`-Puffer zur√ºcksetzt, werden alle `*_memo` ung√ºltig und m√ºssen
ebenfalls zur√ºckgesetzt werden!

## Semantische Pr√§dikate

Problem in Java: `enum` ab Java5 Schl√ºsselwort (vorher als
Identifier-Name verwendbar)

``` antlr
prog : (enumDecl | stat)+ ;
stat : ... ;

enumDecl : ENUM id '{' id (',' id)* '}' ;
```

Wie kann ich eine Grammatik bauen, die sowohl f√ºr Java5 und sp√§ter als
auch f√ºr die Vorg√§nger von Java5 funktioniert?

Angenommen, man h√§tte eine Hilfsfunktion (‚ÄúPr√§dikat‚Äù), mit denen man aus
dem Kontext heraus die Unterscheidung treffen kann, dann w√ºrde die
Umsetzung der Regel ungef√§hr so aussehen:

``` python
def prog():
    if lookahead(1) == ENUM and java5: enumDecl()
    else: stat()
```

## Semantische Pr√§dikate in ANTLR

### Semantische Pr√§dikate in Parser-Regeln

``` antlr
@parser::members {public static boolean java5;}

prog : ({java5}? enumDecl | stat)+ ;
stat : ... ;

enumDecl : ENUM id '{' id (',' id)* '}' ;
```

Pr√§dikate in Parser-Regeln aktivieren bzw. deaktivieren alles, was nach
der Abfrage des Pr√§dikats gematcht werden k√∂nnte.

### Semantische Pr√§dikate in Lexer-Regeln

Alternativ f√ºr Lexer-Regeln:

``` antlr
ENUM : 'enum' {java5}? ;
ID   : [a-zA-Z]+ ;
```

Bei Token kommt das Pr√§dikat erst am rechten Ende einer Lexer-Regel vor,
da der Lexer keine Vorhersage macht, sondern nach dem l√§ngsten Match
sucht und die Entscheidung erst trifft, wenn das ganze Token gesehen
wurde. Bei Parser-Regeln steht das Pr√§dikat links vor der entsprechenden
Alternative, da der Parser mit Hilfe des Lookaheads Vorhersagen trifft,
welche Regel/Alternative zutrifft.

*Anmerkung*: Hier wurden nur Variablen eingesetzt, es k√∂nnen aber auch
Methoden/Funktionen genutzt werden. In Verbindung mit einer
Symboltabelle ([‚ÄúSymboltabellen‚Äù](cb_symboltabellen1.html)) und/oder mit
Attributen und Aktionen in der Grammatik
([‚ÄúAttribute‚Äù](cb_attribute.html) und [‚ÄúInterpreter:
Attribute+Aktionen‚Äù](cb_interpreter2.html)) hat man hier ein m√§chtiges
Hilfswerkzeug!

## Wrap-Up

- LL(1) und LL(k): Erweiterungen
  - Dynamischer Lookahead: BT-Parser mit Packrat-Erg√§nzung
  - Semantische Pr√§dikate zum Abschalten von Alternativen

## üìñ Zum Nachlesen

- Parr ([2010](#ref-Parr2010)): Kapitel 3
- Parr ([2014](#ref-Parr2014))
- Mogensen ([2017](#ref-Mogensen2017)): Kapitel 2 (insbesondere
  Abschnitte 2.3 bis (einschlie√ülich) 2.19)
- Aho u.¬†a. ([2023](#ref-Aho2023)): Abschnitte 2.4 und 4.4
- Grune u.¬†a. ([2012](#ref-Grune2012)): Abschnitte 3.1 bis
  (einschlie√ülich) 3.4
- Ford ([2006](#ref-Packrat2006))

> [!NOTE]
>
> <details>
>
> <summary><strong>‚úÖ Lernziele</strong></summary>
>
> - k3: Ich kann LL(1)- und LL(k)-Parser implementieren
> - k3: Ich kann einen dynamischen Lookahead mittels Backtracking
>   erreichen und die Laufzeiteigenschaften mit Packrat verbessern
> - k3: Ich kann semantische Pr√§dikate zum (De-) Aktivieren von Regeln
>   oder Token einsetzen
>
> </details>

------------------------------------------------------------------------

> [!NOTE]
>
> <details>
>
> <summary><strong>üëÄ Quellen</strong></summary>
>
> <div id="refs" class="references csl-bib-body hanging-indent"
> entry-spacing="0">
>
> <div id="ref-Aho2023" class="csl-entry">
>
> Aho, A. V., M. S. Lam, R. Sethi, J. D. Ullman, und S. Bansal. 2023.
> *Compilers: Principles, Techniques, and Tools, Updated 2nd Edition by
> Pearson*. Pearson India.
> <https://learning.oreilly.com/library/view/compilers-principles-techniques/9789357054881/>.
>
> </div>
>
> <div id="ref-Packrat2006" class="csl-entry">
>
> Ford, B. 2006. ‚ÄûPackrat Parsing: Simple, Powerful, Lazy, Linear Time‚Äú.
> *CoRR* abs/cs/0603077. <http://arxiv.org/abs/cs/0603077>.
>
> </div>
>
> <div id="ref-Grune2012" class="csl-entry">
>
> Grune, D., K. van Reeuwijk, H. E. Bal, C. J. H. Jacobs, und K.
> Langendoen. 2012. *Modern Compiler Design*. Springer.
>
> </div>
>
> <div id="ref-Mogensen2017" class="csl-entry">
>
> Mogensen, T. 2017. *Introduction to Compiler Design*. Springer.
> <https://doi.org/10.1007/978-3-319-66966-3>.
>
> </div>
>
> <div id="ref-Parr2010" class="csl-entry">
>
> Parr, T. 2010. *Language Implementation Patterns*. Pragmatic
> Bookshelf.
> <https://learning.oreilly.com/library/view/language-implementation-patterns/9781680500097/>.
>
> </div>
>
> <div id="ref-Parr2014" class="csl-entry">
>
> ‚Äî‚Äî‚Äî. 2014. *The Definitive ANTLR 4 Reference*. Pragmatic Bookshelf.
> <https://learning.oreilly.com/library/view/the-definitive-antlr/9781941222621/>.
>
> </div>
>
> </div>
>
> </details>

------------------------------------------------------------------------

<img src="https://licensebuttons.net/l/by-sa/4.0/88x31.png" width="10%">

Unless otherwise noted, this work is licensed under CC BY-SA 4.0.

<blockquote><p><sup><sub><strong>Last modified:</strong> 0db2fe0 (tooling: rename 'origin' to 'credits', 2025-08-22)<br></sub></sup></p></blockquote>
